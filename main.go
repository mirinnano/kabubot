package main

import (
	"context"
	"crypto/sha256"
	"encoding/hex"
	"fmt"
	"log"
	"net/url"
	"strings"
	"sync"
	"time"
	"bot/status"
	"github.com/glebarez/sqlite"
	"github.com/gocolly/colly/v2"
	"github.com/spf13/viper"
	"go.uber.org/zap"
	"gorm.io/gorm"

	"bot/config"
	"bot/handlers"
	"bot/services"

	"github.com/bwmarrin/discordgo"
)

var (
	// å„ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ã¯ filterParam ã‚’å—ã‘å–ã‚‹ã‚·ã‚°ãƒãƒãƒ£ã«çµ±ä¸€
	sites = map[string]func(*zap.Logger, string) []map[string]interface{}{
		"kabutan":    scrapeKabutanArticles,
		"kabutan_ir": scrapeKabutanIR,
	}
	errMutex sync.Mutex
	db       *gorm.DB
)

func initDB() {
	var err error
	db, err = gorm.Open(sqlite.Open("articles.db"), &gorm.Config{})
	if err != nil {
		log.Fatalf("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã«å¤±æ•—ã—ã¾ã—ãŸ: %v", err)
	}

	// è‡ªå‹•ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
	db.AutoMigrate(&Article{})
}

func main() {
	config.InitConfig()
	if err := config.ValidateConfig(); err != nil {
		log.Fatalf("è¨­å®šæ¤œè¨¼ã‚¨ãƒ©ãƒ¼: %v", err)
	}

	logger := config.GetLogger()
	defer logger.Sync()

	initDB()

	// Discordã‚»ãƒƒã‚·ãƒ§ãƒ³ã®åˆæœŸåŒ–ã¨æ¥ç¶š
	discord := handlers.InitDiscordSession(logger)
	if err := discord.Open(); err != nil {
		logger.Fatal("Discordæ¥ç¶šã«å¤±æ•—ã—ã¾ã—ãŸ",
			zap.Error(err),
			zap.String("ãƒˆãƒ¼ã‚¯ãƒ³", viper.GetString("discord.token")),
			zap.String("è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«", viper.ConfigFileUsed()),
		)
		defer discord.Close()
		return
	}

	discord.AddHandler(func(s *discordgo.Session, r *discordgo.Ready) {
		logger.Info("DiscordãƒœãƒƒãƒˆãŒã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã§ã™",
			zap.String("ãƒ¦ãƒ¼ã‚¶ãƒ¼å", r.User.Username),
			zap.String("ãƒ¦ãƒ¼ã‚¶ãƒ¼ID", r.User.ID),
			zap.Float64("æ¥ç¶šé…å»¶(ms)", s.HeartbeatLatency().Seconds()*1000),
		)
	})
	

	var cfg config.Config
	if err := viper.Unmarshal(&cfg); err != nil {
		logger.Fatal("è¨­å®šã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ", zap.Error(err))
	}
	summaryService := services.NewSummaryService(&cfg.AI, logger, db)
	scheduler := services.NewScheduler(discord, logger, summaryService)

	// ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å–å¾—å¯èƒ½
	kabutanFilter := viper.GetString("kabutan.filter") // é€šå¸¸ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
	irFilter := viper.GetString("kabutan.ir_filter")   // IRå°‚ç”¨ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼

	// é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ï¼ˆè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰é–“éš”ã‚’å–å¾—ï¼‰
	scheduler.AddTask(viper.GetString("scraping.interval"), func() {
		articles := scrapeKabutanArticles(logger, kabutanFilter)
		status.UpdatePlayingStatus(discord)
		if len(articles) > 0 {
			logger.Info("é€šå¸¸ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°çµæœ", zap.Int("è¨˜äº‹æ•°", len(articles)))
			processAndNotify(discord, logger, articles)
		}
	})

	// ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ IRé€šçŸ¥ãƒ¢ãƒ¼ãƒ‰ï¼ˆå¸‚å ´æ™‚é–“ä¸­30ç§’é–“éš”ï¼‰
	// 6æ™‚é–“å‰ã‹ã‚‰ã®è¨˜äº‹ã‚’è¦ç´„ã™ã‚‹ã‚¿ã‚¹ã‚¯
	scheduler.AddTask("0 */6 * * *", func() {
		var articles []Article
		sixHoursAgo := time.Now().Add(-6 * time.Hour)

		if result := db.Where("published_at >= ? AND summary = ''", sixHoursAgo).Find(&articles); result.Error != nil {
			logger.Error("è¦ç´„å¯¾è±¡è¨˜äº‹ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ", zap.Error(result.Error))
			return
		}

		logger.Info("è¦ç´„å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™",
			zap.Int("å¯¾è±¡è¨˜äº‹æ•°", len(articles)),
			zap.Time("åŸºæº–æ™‚åˆ»", sixHoursAgo))

		for _, article := range articles {
			if err := summaryService.GenerateAndStoreSummary(context.Background(), int(article.ID), article.Body); err != nil {
				logger.Error("è¨˜äº‹è¦ç´„ã«å¤±æ•—ã—ã¾ã—ãŸ",
					zap.Int("article_id", int(article.ID)),
					zap.Error(err))
			}
		}
	})

	// ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ IRé€šçŸ¥ãƒ¢ãƒ¼ãƒ‰ï¼ˆå¸‚å ´æ™‚é–“ä¸­30ç§’é–“éš”ï¼‰
	scheduler.AddTask("*/1 * * * *", func() {
		articles := scrapeKabutanIR(logger, irFilter)
		
		if len(articles) > 0 {
			logger.Info("ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ IRæ¤œå‡º", zap.Int("ä»¶æ•°", len(articles)))
			// ç·Šæ€¥è¨˜äº‹ã®ã¿åˆ¥ãƒ«ãƒ¼ãƒˆã§é€šçŸ¥
			processUrgentNotifications(discord, logger, articles)
		}
	})

	// 6æ™‚é–“ã”ã¨ã®æœ¬æ–‡å†å–å¾—ã‚¿ã‚¹ã‚¯
	scheduler.AddTask("0 */6 * * *", func() {
		var articles []Article
		twentyFourHoursAgo := time.Now().Add(-24 * time.Hour)

		// æœ€çµ‚ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‹ã‚‰24æ™‚é–“ä»¥ä¸ŠçµŒéã‹ã¤ãƒªãƒˆãƒ©ã‚¤å›æ•°3å›æœªæº€ã®è¨˜äº‹ã‚’å–å¾—
		if result := db.Where("last_scraped_at < ? AND retry_count < ?", twentyFourHoursAgo, 3).Find(&articles); result.Error != nil {
			logger.Error("å†ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å¯¾è±¡è¨˜äº‹ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ", zap.Error(result.Error))
			return
		}

		logger.Info("æœ¬æ–‡ã®å†ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚’é–‹å§‹ã—ã¾ã™",
			zap.Int("å¯¾è±¡è¨˜äº‹æ•°", len(articles)),
			zap.Time("åŸºæº–æ™‚åˆ»", twentyFourHoursAgo))

		for _, article := range articles {
			newBody := getArticleBody(logger, article.URL)
			if newBody != "" && newBody != article.Body {
				// æœ¬æ–‡ãŒæ›´æ–°ã•ã‚Œã¦ã„ã‚‹å ´åˆã®ã¿ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’æ›´æ–°
				updateResult := db.Model(&article).Updates(map[string]interface{}{
					"body":            newBody,
					"last_scraped_at": time.Now(),
					"retry_count":     gorm.Expr("retry_count + 1"),
				})

				if updateResult.Error != nil {
					logger.Error("æœ¬æ–‡æ›´æ–°ã«å¤±æ•—ã—ã¾ã—ãŸ",
						zap.Int("article_id", int(article.ID)),
						zap.Error(updateResult.Error))
				} else {
					logger.Info("æœ¬æ–‡ã‚’æ­£å¸¸ã«æ›´æ–°ã—ã¾ã—ãŸ",
						zap.Int("article_id", int(article.ID)),
						zap.Int("æ–‡å­—æ•°", len(newBody)))
				}
			}
		}
	})
	scheduler.Start()
	// ãƒ¡ã‚¤ãƒ³ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’ãƒ–ãƒ­ãƒƒã‚¯ï¼ˆãƒãƒ¼ãƒˆãƒ“ãƒ¼ãƒˆä»˜ãï¼‰
	logger.Info("ãƒ¡ã‚¤ãƒ³ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’èµ·å‹•ã—ã¾ã—ãŸ")
	ticker := time.NewTicker(5 * time.Minute)
	defer ticker.Stop()

	for range ticker.C {
		logger.Info("ã‚·ã‚¹ãƒ†ãƒ ã¯å‹•ä½œä¸­ã§ã™",
			zap.Time("æœ€çµ‚ãƒã‚§ãƒƒã‚¯", time.Now()),
		)
	}
}

// debugä»˜ã scrapeKabutanArticles é–¢æ•°ï¼ˆãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³ç„¡åŠ¹åŒ–ï¼‰
func scrapeKabutanArticles(logger *zap.Logger, filterParam string) []map[string]interface{} {
	baseURL := "https://kabutan.jp/news/marketnews/"
	startURL := baseURL
	if filterParam != "" {
		startURL += "?" + filterParam
	}

	articles := make([]map[string]interface{}, 0)

	c := colly.NewCollector(
		colly.UserAgent("Mozilla/5.0"),
	)

	c.OnRequest(func(r *colly.Request) {
		logger.Info("è¨ªå•é–‹å§‹", zap.String("url", r.URL.String()))
	})

	c.OnHTML(".s_news_list.mgbt0 tr", func(e *colly.HTMLElement) {
		article := make(map[string]interface{})

		// æ—¥æ™‚
		datetime := e.ChildAttr("td.news_time time", "datetime")
		if datetime != "" {
			article["date"] = datetime
		}

		// ã‚«ãƒ†ã‚´ãƒª
		category := e.ChildText("td:nth-child(2) div.newslist_ctg")
		if category != "" {
			article["category"] = category
		}

	

		// éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰

		// ã‚¿ã‚¤ãƒˆãƒ« + URL
		title := e.ChildText("td:nth-child(3) a")
		href := e.ChildAttr("td:nth-child(3) a", "href")
		if title != "" {
			article["title"] = title
		}
		if href != "" {
			u, _ := url.Parse(baseURL)
			article["url"] = u.ResolveReference(&url.URL{Path: href}).String()
		}

		// å¿…é ˆé …ç›®ãƒã‚§ãƒƒã‚¯
		if !hasRequiredFields(article) {
			logger.Info("å¿…é ˆé …ç›®ä¸è¶³ã€ã‚¹ã‚­ãƒƒãƒ—", zap.Any("article", article))
			return
		}

		// URLæ­£è¦åŒ–
		norm, err := normalizeURL(article["url"].(string))
		if err != nil {
			logger.Warn("URLæ­£è¦åŒ–ã‚¨ãƒ©ãƒ¼", zap.String("url", article["url"].(string)), zap.Error(err))
			return
		}
		article["url"] = norm

		// é‡è¤‡ãƒã‚§ãƒƒã‚¯
		hash := generateHash(article["title"].(string), article["url"].(string), norm)
		var exist Article
		if err := db.Where("url = ? OR hash = ?", norm, hash).First(&exist).Error; err == nil {
			logger.Info("ã™ã§ã«å­˜åœ¨ã™ã‚‹è¨˜äº‹ã€ã‚¹ã‚­ãƒƒãƒ—", zap.String("title", article["title"].(string)))
			return
		}

		// DBä¿å­˜
		var pub time.Time
		if ds, ok := article["date"].(string); ok && ds != "" {
			pt, err := time.Parse(time.RFC3339, ds)
			if err != nil {
				logger.Warn("æ—¥æ™‚ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼", zap.String("date", ds), zap.Error(err))
				return
			}
			pub = pt
		}

		errMutex.Lock()
		defer errMutex.Unlock()

		if err := db.Create(&Article{
			Title:       article["title"].(string),
			URL:         norm,
			Hash:        hash,
			Content:     fmt.Sprintf("ã‚«ãƒ†ã‚´ãƒª: %s", article["category"]),
			Category:    article["category"].(string),
			PublishedAt: pub,
		}).Error; err != nil {
			logger.Error("è¨˜äº‹ä¿å­˜å¤±æ•—", zap.String("title", article["title"].(string)), zap.Error(err))
		} else {
			logger.Info("è¨˜äº‹ä¿å­˜æˆåŠŸ", zap.String("title", article["title"].(string)))
			articles = append(articles, article)
		}
	})

	c.OnError(func(r *colly.Response, err error) {
		logger.Error("ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼", zap.String("url", r.Request.URL.String()), zap.Int("status", r.StatusCode), zap.Error(err))
	})

	err := c.Visit(startURL)
	if err != nil {
		logger.Error("ã‚µã‚¤ãƒˆè¨ªå•ã‚¨ãƒ©ãƒ¼", zap.Error(err))
		return nil
	}

	return articles
}

// scrapeKabutanIR ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ IRç”¨ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼
func scrapeKabutanIR(logger *zap.Logger, filterParam string) []map[string]interface{} {
	c := colly.NewCollector(
		colly.AllowedDomains("kabutan.jp"),
		colly.Async(true),
		colly.CacheDir("./.cache"),
	)
	logger.Info("set")

	c.Limit(&colly.LimitRule{
		DomainGlob:  "*",
		Parallelism: viper.GetInt("scraping.parallelism"),
		RandomDelay: time.Duration(viper.GetInt("scraping.delay_seconds")) * time.Second,
	})

	articles := make([]map[string]interface{}, 0)
	baseURL := "https://kabutan.jp/news/"

	c.OnHTML("#news_contents .s_news_list tr", func(e *colly.HTMLElement) {
		article := map[string]interface{}{
			"date":       e.ChildAttr("td.news_time time", "datetime"),
			"category":   e.ChildText("td:nth-child(2) div.newslist_ctg"),
			"is_urgent":  strings.Contains(e.ChildAttr("td:nth-child(2) div.newslist_ctg", "class"), "kk_b"),
			"stock_code": e.ChildAttr("td:nth-child(3)", "data-code"),
			"title":      e.ChildText("td:nth-child(4) a"),
			"url":        e.Request.AbsoluteURL(e.ChildAttr("td:nth-child(4) a", "href")),
		}

		if !hasRequiredFields(article) {
			logger.Warn("å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ¤œè¨¼ã‚¨ãƒ©ãƒ¼ï¼ˆIRè¨˜äº‹ï¼‰", zap.Any("article", article))
			return
		}

		norm, err := normalizeURL(article["url"].(string))
		if err != nil {
			logger.Warn("IRè¨˜äº‹URLæ­£è¦åŒ–ã‚¨ãƒ©ãƒ¼", zap.Error(err), zap.String("original_url", article["url"].(string)))
			return
		}
		article["url"] = norm

		hash := generateHash(article["title"].(string), article["url"].(string), norm)
		var exist Article
		if err := db.Where("url = ? OR hash = ?", norm, hash).First(&exist).Error; err == nil {
			logger.Info("é‡è¤‡IRè¨˜äº‹ã‚’ã‚¹ã‚­ãƒƒãƒ—", zap.String("title", article["title"].(string)), zap.String("hash", hash))
			return
		}

		errMutex.Lock()
		defer errMutex.Unlock()
		maxIRArticles := viper.GetInt("scraping.max_articles.ir")
		if len(articles) >= maxIRArticles {
			logger.Info("IRè¨˜äº‹æœ€å¤§å–å¾—æ•°ã«é”ã—ãŸãŸã‚å‡¦ç†ã‚’åœæ­¢",
				zap.Int("max_articles", maxIRArticles))
			return
		}

		if err := db.Create(&Article{
			Title:       article["title"].(string),
			URL:         norm,
			Hash:        hash,
			Content:     fmt.Sprintf("IRã‚«ãƒ†ã‚´ãƒª: %s", article["category"].(string)),
			Category:    article["category"].(string),
			PublishedAt: time.Now(),
		}).Error; err != nil {
			logger.Error("IRè¨˜äº‹ä¿å­˜å¤±æ•—", zap.Error(err))
		} else {
			articles = append(articles, article)
			if len(articles) >= maxIRArticles {
				logger.Info("IRè¨˜äº‹æœ€å¤§å–å¾—æ•°ã«é”ã—ãŸãŸã‚å‡¦ç†ã‚’åœæ­¢",
					zap.Int("max_articles", maxIRArticles))
				return
			}
		}
	})

	// ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³ç„¡åŠ¹åŒ–ï¼ˆé«˜é »åº¦ã‚¯ãƒ­ãƒ¼ãƒªãƒ³ã‚°ã®ãŸã‚ï¼‰
	// c.OnHTML(".pagination a[href]", func(e *colly.HTMLElement) {})

	startURL := baseURL
	if filterParam != "" {
		startURL += "?" + filterParam
	}
	c.Visit(startURL)
	c.Wait()

	return articles
}

func hasRequiredFields(article map[string]interface{}) bool {
	required := map[string]func(interface{}) bool{
		"date":     func(v interface{}) bool { _, ok := v.(string); return ok },
		"category": func(v interface{}) bool { _, ok := v.(string); return ok },
		"title":    func(v interface{}) bool { _, ok := v.(string); return ok },
		"url":      func(v interface{}) bool { _, ok := v.(string); return ok },
	}

	for key, validate := range required {
		val, exists := article[key]
		if !exists || !validate(val) {
			return false
		}
	}

	// æ—¥ä»˜å½¢å¼ã®æ¤œè¨¼
	if _, err := time.Parse(time.RFC3339, article["date"].(string)); err != nil {
		return false
	}

	return true
}

func normalizeURL(rawURL string) (string, error) {
	u, err := url.Parse(rawURL)
	if err != nil {
		return "", err
	}
	decodedPath, err := url.PathUnescape(u.EscapedPath())
	if err != nil {
		return "", err
	}
	decodedPath = strings.ReplaceAll(decodedPath, "%3F", "?")
	u.Path = decodedPath

	if u.RawQuery != "" {
		return fmt.Sprintf("%s://%s%s?%s", u.Scheme, u.Host, u.Path, u.RawQuery), nil
	}
	return fmt.Sprintf("%s://%s%s", u.Scheme, u.Host, u.Path), nil
}

func truncateString(s string, max int) string {
	if len(s) <= max {
		return s
	}
	return s[:max] + "..." // åˆ‡ã‚Šè©°ã‚æœ«å°¾ã«çœç•¥è¨˜å·ã‚’è¿½åŠ 
}

func getSummaryForDisplay(article map[string]interface{}) string {
	if summary, ok := article["summary"].(string); ok && summary != "" {
		return summary
	}
	return "è¦ç´„ç”Ÿæˆä¸­... ã—ã°ã‚‰ããŠå¾…ã¡ãã ã•ã„"
}

func getArticleBody(logger *zap.Logger, url string) string {
	c := colly.NewCollector(
		colly.Async(true),
		colly.MaxDepth(2),
	)

	c.Limit(&colly.LimitRule{
		DomainGlob:  "*",
		Parallelism: 3,
		RandomDelay: 1 * time.Second,
	})

	var body strings.Builder
	var wg sync.WaitGroup
	wg.Add(1)

	c.OnHTML("#news_body", func(e *colly.HTMLElement) {
		defer wg.Done()
		content := strings.TrimSpace(e.Text)
		if content == "" {
			logger.Warn("æœ¬æ–‡ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒç©ºã§ã™", zap.String("url", url))
			return
		}
		body.WriteString(content)
	})

	c.OnError(func(r *colly.Response, err error) {
		defer wg.Done()
		logger.Error("è¨˜äº‹æœ¬æ–‡ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ",
			zap.String("url", url),
			zap.Int("status_code", r.StatusCode),
			zap.Error(err))
	})

	if err := c.Visit(url); err != nil {
		logger.Error("ãƒªã‚¯ã‚¨ã‚¹ãƒˆé–‹å§‹ã«å¤±æ•—ã—ã¾ã—ãŸ",
			zap.String("url", url),
			zap.Error(err))
		return ""
	}

	wg.Wait()
	return body.String()
}

func generateHash(title, rawURL, normalizedURL string) string {
	h := sha256.New()
	h.Write([]byte(title))
	h.Write([]byte(rawURL))
	h.Write([]byte(normalizedURL))
	return hex.EncodeToString(h.Sum(nil))
}

func processAndNotify(discord *discordgo.Session, logger *zap.Logger, data []map[string]interface{}) {
	channelID := viper.GetString("discord.alert_channel")
	for _, article := range data {
		// ã‚«ãƒ©ãƒ¼ãƒãƒƒãƒ”ãƒ³ã‚°
		color := 0x00FF00 // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆç·‘

		embed := &discordgo.MessageEmbed{
			Author: &discordgo.MessageEmbedAuthor{
					Name:    "é€Ÿå ±",
					IconURL: "https://kabutan.jp/favicon.ico",
			},
			Title:       article["title"].(string),
			URL:         article["url"].(string),
			Description: fmt.Sprintf("**ã‚«ãƒ†ã‚´ãƒª**: %s\n", article["category"].(string)),  // â†ã“ã“ã§é–‰ã˜ã‚‹
			Fields: []*discordgo.MessageEmbedField{                                        // â†ãã—ã¦ã‚«ãƒ³ãƒ
					{
							Name:   "å…¬é–‹æ—¥æ™‚",
							Value:  article["date"].(string),
							Inline: true,
					},
					// å¿…è¦ãªã‚‰ä»–ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚‚
			},
			Color:     color,
			Timestamp: article["date"].(string),
			Footer:    &discordgo.MessageEmbedFooter{Text: "Powered by Kabutan Scraper ver1.1.0"},
	}
	
		if _, err := discord.ChannelMessageSendEmbed(channelID, embed); err != nil {
			logger.Error("Discordé€šçŸ¥ã«å¤±æ•—", zap.Error(err))
		}
	}
}

func processUrgentNotifications(discord *discordgo.Session, logger *zap.Logger, data []map[string]interface{}) {
	channelID := viper.GetString("discord.urgent_channel")
	if channelID == "" {
		channelID = viper.GetString("discord.alert_channel")
	}

	for _, article := range data {
		// å‹ã‚¢ã‚µãƒ¼ã‚·ãƒ§ãƒ³ã®å‰ã«å­˜åœ¨ãƒã‚§ãƒƒã‚¯ã‚’è¿½åŠ 
		urgent, _ := article["is_urgent"].(bool)
		if !urgent {
			continue
		}

		// ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®å­˜åœ¨ãƒã‚§ãƒƒã‚¯ã‚’è¿½åŠ 
		var (
			title, url, stockCode, category, body, date string
			ok                                          bool
		)

		if title, ok = article["title"].(string); !ok {
			logger.Error("è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«ãŒä¸æ­£ãªå½¢å¼ã§ã™", zap.Any("article", article))
			continue
		}
		if url, ok = article["url"].(string); !ok {
			logger.Error("è¨˜äº‹URLãŒä¸æ­£ãªå½¢å¼ã§ã™", zap.Any("article", article))
			continue
		}
		if stockCode, ok = article["stock_code"].(string); !ok {
			logger.Error("éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ãŒä¸æ­£ãªå½¢å¼ã§ã™", zap.Any("article", article))
			continue
		}
		if category, ok = article["category"].(string); !ok {
			logger.Error("ã‚«ãƒ†ã‚´ãƒªãŒä¸æ­£ãªå½¢å¼ã§ã™", zap.Any("article", article))
			continue
		}
		if body, ok = article["body"].(string); !ok {
			body = "æœ¬æ–‡ãŒã‚ã‚Šã¾ã›ã‚“"
		}
		if date, ok = article["date"].(string); !ok {
			date = "æ—¥æ™‚ä¸æ˜"
		}

		embed := &discordgo.MessageEmbed{
			Author: &discordgo.MessageEmbedAuthor{
				Name:    "ğŸš¨ ç·Šæ€¥IRé€šçŸ¥ ğŸš¨",
				IconURL: "https://kabutan.jp/favicon.ico",
			},
			Title: title,
			URL:   url,
			Description: fmt.Sprintf("**éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰**: %s\n**ã‚«ãƒ†ã‚´ãƒª**: %s\n**æœ¬æ–‡**:\n%s",
				stockCode,
				category,
				truncateString(body, 1000)),
			Fields: []*discordgo.MessageEmbedField{
				{Name: "ç™ºè¡¨æ™‚åˆ»", Value: date, Inline: true},
			},
			Color:     0xFF0000,
			Timestamp: date,
			Footer:    &discordgo.MessageEmbedFooter{Text: "ver1.0.2"},
		}
		if _, err := discord.ChannelMessageSendEmbed(channelID, embed); err != nil {
			logger.Error("ç·Šæ€¥é€šçŸ¥ã«å¤±æ•—",
				zap.Error(err),
				zap.String("title", title),
				zap.String("url", url))
		}
	}
}

type Article struct {
	ID            uint   `gorm:"primaryKey"`
	Site          string `gorm:"index"`
	Title         string
	URL           string `gorm:"uniqueIndex;size:500"`
	Hash          string `gorm:"uniqueIndex;size:64"`
	Content       string
	Body          string `gorm:"type:text"`
	Summary       string `gorm:"type:text"`
	Category      string
	PublishedAt   time.Time
	CreatedAt     time.Time
	UpdatedAt     time.Time
	LastScrapedAt time.Time // æœ€çµ‚ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°æ—¥æ™‚ã‚’è¿½è·¡
	RetryCount    int       // ãƒªãƒˆãƒ©ã‚¤å›æ•°ã‚’è¿½è·¡
}
